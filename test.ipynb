{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_HOME = os.path.abspath(\"G:\\Other Games\\spark-3.4.1-bin-hadoop3\\spark-3.4.1-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_status_df = pd.read_csv(\"./assets/store status.csv\")\n",
    "open_hours_df = pd.read_csv(\"./assets/Menu hours.csv\")\n",
    "time_zone_df = pd.read_csv(\"./assets/bq-results-20230125-202210-1674678181880.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13559"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_zone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>day</th>\n",
       "      <th>start_time_local</th>\n",
       "      <th>end_time_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, day, start_time_local, end_time_local]\n",
       "Index: []"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_hours_df.head()\n",
    "open_hours_df[open_hours_df['store_id'] == '8419537941919820732']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>timezone_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, timezone_str]\n",
       "Index: []"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_zone_df.head()\n",
    "time_zone_df[time_zone_df['store_id'] == '525217215046186225']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(store_status_df, open_hours_df, how=\"left\", on=\"store_id\")\n",
    "result = pd.merge(result, time_zone_df, how='left', on=\"store_id\")\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>day</th>\n",
       "      <th>start_time_local</th>\n",
       "      <th>end_time_local</th>\n",
       "      <th>timezone_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-22 12:09:39.388884 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2057963137235512954</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-21 17:15:29.921161 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>7815590034868021689</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-21 17:15:39.285005 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7493928216510270665</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-21 17:15:43.777556 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>6656463669299127947</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 17:01:33.08729 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820024</th>\n",
       "      <td>7562603514970763933</td>\n",
       "      <td>inactive</td>\n",
       "      <td>2023-01-22 03:00:53.021117 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820049</th>\n",
       "      <td>4658864072483512739</td>\n",
       "      <td>inactive</td>\n",
       "      <td>2023-01-19 14:09:05.647772 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820249</th>\n",
       "      <td>7758862105355689282</td>\n",
       "      <td>inactive</td>\n",
       "      <td>2023-01-25 11:02:18.389155 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820379</th>\n",
       "      <td>6231179318258751370</td>\n",
       "      <td>inactive</td>\n",
       "      <td>2023-01-19 08:04:58.142037 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820428</th>\n",
       "      <td>8268157534125276307</td>\n",
       "      <td>inactive</td>\n",
       "      <td>2023-01-19 06:05:39.340617 UTC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81931 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     store_id    status                   timestamp_utc  day  \\\n",
       "0         8419537941919820732    active  2023-01-22 12:09:39.388884 UTC  NaN   \n",
       "81        2057963137235512954    active  2023-01-21 17:15:29.921161 UTC  NaN   \n",
       "83        7815590034868021689    active  2023-01-21 17:15:39.285005 UTC  NaN   \n",
       "84        7493928216510270665    active  2023-01-21 17:15:43.777556 UTC  NaN   \n",
       "222       6656463669299127947    active   2023-01-25 17:01:33.08729 UTC  NaN   \n",
       "...                       ...       ...                             ...  ...   \n",
       "11820024  7562603514970763933  inactive  2023-01-22 03:00:53.021117 UTC  NaN   \n",
       "11820049  4658864072483512739  inactive  2023-01-19 14:09:05.647772 UTC  NaN   \n",
       "11820249  7758862105355689282  inactive  2023-01-25 11:02:18.389155 UTC  NaN   \n",
       "11820379  6231179318258751370  inactive  2023-01-19 08:04:58.142037 UTC  NaN   \n",
       "11820428  8268157534125276307  inactive  2023-01-19 06:05:39.340617 UTC  NaN   \n",
       "\n",
       "         start_time_local end_time_local timezone_str  \n",
       "0                     NaN            NaN          NaN  \n",
       "81                    NaN            NaN          NaN  \n",
       "83                    NaN            NaN          NaN  \n",
       "84                    NaN            NaN          NaN  \n",
       "222                   NaN            NaN          NaN  \n",
       "...                   ...            ...          ...  \n",
       "11820024              NaN            NaN          NaN  \n",
       "11820049              NaN            NaN          NaN  \n",
       "11820249              NaN            NaN          NaN  \n",
       "11820379              NaN            NaN          NaN  \n",
       "11820428              NaN            NaN          NaN  \n",
       "\n",
       "[81931 rows x 7 columns]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.loc[result['timezone_str'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['day'].fillna(6, inplace=True)\n",
    "result['start_time_local'].fillna('00:00:00', inplace=True)\n",
    "result['end_time_local'].fillna('23:59:59', inplace=True)\n",
    "result['timezone_str'].fillna('America/Chicago', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_id                       2873839205725435068\n",
       "status                                      active\n",
       "timestamp_utc       2023-01-25 05:07:59.711411 UTC\n",
       "day                                            0.0\n",
       "start_time_local                          16:00:00\n",
       "end_time_local                            21:00:00\n",
       "timezone_str                      America/New_York\n",
       "Name: 1820758, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f = result.query('store_id == 7562603514970763933')\n",
    "# f.query('status == \"active\"')\n",
    "result.iloc[-10002300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1674389379.388884"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert string to timestamp\n",
    "from datetime import datetime, timezone\n",
    "something = store_status_df['timestamp_utc'][0].split(' ')\n",
    "something.pop(-1)\n",
    "time = ' '.join(something)\n",
    "FORMAT = '%Y-%m-%d %H:%M:%S.%f'\n",
    "ts = datetime.strptime(time, FORMAT).replace(tzinfo=timezone.utc).timestamp()\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     store_id    status                   timestamp_utc  day  \\\n",
      "9813325   4715335257465089466  inactive    2023-01-18 19:50:54.2586 UTC  2.0   \n",
      "9813334   4715335257465089466  inactive    2023-01-18 19:50:54.2586 UTC  2.0   \n",
      "10682103  4715335257465089466  inactive  2023-01-18 20:30:36.077544 UTC  2.0   \n",
      "10682112  4715335257465089466  inactive  2023-01-18 20:30:36.077544 UTC  2.0   \n",
      "10450999  4715335257465089466  inactive   2023-01-18 21:10:07.73541 UTC  2.0   \n",
      "...                       ...       ...                             ...  ...   \n",
      "10244183  4715335257465089466  inactive  2023-01-25 16:12:25.133302 UTC  2.0   \n",
      "9948768   4715335257465089466  inactive  2023-01-25 17:10:19.048211 UTC  2.0   \n",
      "9948759   4715335257465089466  inactive  2023-01-25 17:10:19.048211 UTC  2.0   \n",
      "9466483   4715335257465089466  inactive  2023-01-25 18:06:38.431991 UTC  2.0   \n",
      "9466474   4715335257465089466  inactive  2023-01-25 18:06:38.431991 UTC  2.0   \n",
      "\n",
      "         start_time_local end_time_local      timezone_str  \n",
      "9813325          00:00:00       02:00:00  America/New_York  \n",
      "9813334          06:00:00       23:59:59  America/New_York  \n",
      "10682103         00:00:00       02:00:00  America/New_York  \n",
      "10682112         06:00:00       23:59:59  America/New_York  \n",
      "10450999         06:00:00       23:59:59  America/New_York  \n",
      "...                   ...            ...               ...  \n",
      "10244183         06:00:00       23:59:59  America/New_York  \n",
      "9948768          06:00:00       23:59:59  America/New_York  \n",
      "9948759          00:00:00       02:00:00  America/New_York  \n",
      "9466483          06:00:00       23:59:59  America/New_York  \n",
      "9466474          00:00:00       02:00:00  America/New_York  \n",
      "\n",
      "[222 rows x 7 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9977"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hello = result.query('store_id == 4715335257465089466 & day == 2').sort_values(by='timestamp_utc', ascending=True)\n",
    "print(hello)\n",
    "hello['timestamp_utc'] = hello.timestamp_utc.str.replace(' UTC', '')\n",
    "hello['timestamp_utc'] = pd.to_datetime(hello['timestamp_utc'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "ts = pd.Series(index=hello['timestamp_utc'])\n",
    "ts = ts.resample('T').mean()\n",
    "ts.interpolate(method='spline', order = 3)\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>day</th>\n",
       "      <th>start_time_local</th>\n",
       "      <th>end_time_local</th>\n",
       "      <th>timezone_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2570517</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-18 20:00:34.808486</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722926</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-18 21:05:21.392845</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3081932</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-18 22:02:47.288035</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666773</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-18 23:00:15.228605</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176289</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-19 00:02:06.425245</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757596</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 14:03:11.846034</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901573</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 15:05:02.050854</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986325</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 16:09:44.183230</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103040</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 17:13:13.759148</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322701</th>\n",
       "      <td>8419537941919820732</td>\n",
       "      <td>active</td>\n",
       "      <td>2023-01-25 18:04:43.111517</td>\n",
       "      <td>7.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>23:59:59</td>\n",
       "      <td>America/Chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    store_id  status              timestamp_utc  day  \\\n",
       "2570517  8419537941919820732  active 2023-01-18 20:00:34.808486  7.0   \n",
       "2722926  8419537941919820732  active 2023-01-18 21:05:21.392845  7.0   \n",
       "3081932  8419537941919820732  active 2023-01-18 22:02:47.288035  7.0   \n",
       "5666773  8419537941919820732  active 2023-01-18 23:00:15.228605  7.0   \n",
       "6176289  8419537941919820732  active 2023-01-19 00:02:06.425245  7.0   \n",
       "...                      ...     ...                        ...  ...   \n",
       "757596   8419537941919820732  active 2023-01-25 14:03:11.846034  7.0   \n",
       "901573   8419537941919820732  active 2023-01-25 15:05:02.050854  7.0   \n",
       "7986325  8419537941919820732  active 2023-01-25 16:09:44.183230  7.0   \n",
       "5103040  8419537941919820732  active 2023-01-25 17:13:13.759148  7.0   \n",
       "3322701  8419537941919820732  active 2023-01-25 18:04:43.111517  7.0   \n",
       "\n",
       "        start_time_local end_time_local     timezone_str  \n",
       "2570517         00:00:00       23:59:59  America/Chicago  \n",
       "2722926         00:00:00       23:59:59  America/Chicago  \n",
       "3081932         00:00:00       23:59:59  America/Chicago  \n",
       "5666773         00:00:00       23:59:59  America/Chicago  \n",
       "6176289         00:00:00       23:59:59  America/Chicago  \n",
       "...                  ...            ...              ...  \n",
       "757596          00:00:00       23:59:59  America/Chicago  \n",
       "901573          00:00:00       23:59:59  America/Chicago  \n",
       "7986325         00:00:00       23:59:59  America/Chicago  \n",
       "5103040         00:00:00       23:59:59  America/Chicago  \n",
       "3322701         00:00:00       23:59:59  America/Chicago  \n",
       "\n",
       "[111 rows x 7 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello = result.query('store_id == 8419537941919820732 & day == 7').sort_values(by='timestamp_utc', ascending=True)\n",
    "hello['timestamp_utc'] = hello.timestamp_utc.str.replace(' UTC', '')\n",
    "hello['timestamp_utc'] = pd.to_datetime(hello['timestamp_utc'], format='%Y-%m-%d %H:%M:%S.%f')\n",
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "## INTERPOLATION LOGIC\n",
    "\n",
    "from io import StringIO\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "output = StringIO()\n",
    "csv_writer = writer(output)\n",
    "header = False\n",
    "counter = 0\n",
    "\n",
    "# for index, row in temp.iterrows():\n",
    "#     if(not header):\n",
    "#       csv_writer.writerow(temp)\n",
    "#       header = True\n",
    "\n",
    "#     csv_writer.writerow(row)\n",
    "#     counter += 1\n",
    "current_store_id = np.nan\n",
    "current_status = np.nan\n",
    "current_day = np.nan\n",
    "current_start_time = np.nan\n",
    "current_end_time = np.nan\n",
    "current_timezone = np.nan\n",
    "\n",
    "for value in ts[\"timestamp_utc\"]:\n",
    "    if not header:\n",
    "        csv_writer.writerow(hello)\n",
    "        header = True\n",
    "    next_value = hello[\"timestamp_utc\"].iat[counter]\n",
    "    if value == next_value.replace(second=0, microsecond=0):\n",
    "        current_store_id = hello[\"store_id\"].iat[counter]\n",
    "        current_status = hello[\"status\"].iat[counter]\n",
    "        current_day = hello[\"day\"].iat[counter]\n",
    "        current_start_time = hello[\"start_time_local\"].iat[counter]\n",
    "        current_end_time = hello[\"end_time_local\"].iat[counter]\n",
    "        current_timezone = hello[\"timezone_str\"].iat[counter]\n",
    "        # temp_dict = {\n",
    "        #     \"store_id\": current_store_id,\n",
    "        #     \"status\": current_status,\n",
    "        #     \"timestamp_utc\": value,\n",
    "        #     \"day\": current_day,\n",
    "        #     \"start_time_local\": current_start_time,\n",
    "        #     \"end_time_local\": current_end_time,\n",
    "        #     \"timezone_str\": current_timezone,\n",
    "        # }\n",
    "        temp_list = [current_store_id, current_status, value, current_day, current_start_time, current_end_time, current_timezone]\n",
    "        csv_writer.writerow(temp_list)\n",
    "        counter += 1\n",
    "    else:\n",
    "        # temp_dict = {\n",
    "        #     \"store_id\": current_store_id,\n",
    "        #     \"status\": current_status,\n",
    "        #     \"timestamp_utc\": value,\n",
    "        #     \"day\": current_day,\n",
    "        #     \"start_time_local\": current_start_time,\n",
    "        #     \"end_time_local\": current_end_time,\n",
    "        #     \"timezone_str\": current_timezone,\n",
    "        # }\n",
    "        temp_list = [current_store_id, current_status, value, current_day, current_start_time, current_end_time, current_timezone]\n",
    "        csv_writer.writerow(temp_list)\n",
    "\n",
    "output.seek(0)  # we need to get back to the start of the BytesIO\n",
    "df = pd.read_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>day</th>\n",
       "      <th>start_time_local</th>\n",
       "      <th>end_time_local</th>\n",
       "      <th>timezone_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [store_id, status, timestamp_utc, day, start_time_local, end_time_local, timezone_str]\n",
       "Index: []"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['status'] == 'active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"start_time_local\"] = pd.to_datetime(df[\"start_time_local\"], format=\"%H:%M:%S\")\n",
    "df[\"end_time_local\"] = pd.to_datetime(df[\"end_time_local\"], format=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "2.0166666666666666\n",
      "0.08402777777777778\n"
     ]
    }
   ],
   "source": [
    "# pytz giving incorrect conversions\n",
    "import dateutil\n",
    "\n",
    "\n",
    "def uptime_or_downtime_last_hour(uptime: bool = True):\n",
    "    df[\"timestamp_utc\"] = pd.to_datetime(\n",
    "        df[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    "    )\n",
    "    df.sort_values(\"timestamp_utc\", ascending=False, inplace=True)\n",
    "    current_day = df[\"timestamp_utc\"].iat[0]\n",
    "    till_day = current_day - datetime.timedelta(hours=1)\n",
    "    from_dates = df.loc[df[\"timestamp_utc\"] > till_day]\n",
    "    nearest_till_day = from_dates.iloc[-1][\"timestamp_utc\"]\n",
    "    something = df.query(\"@nearest_till_day <= timestamp_utc <= @current_day\")\n",
    "    if uptime:\n",
    "        return len(something[something[\"status\"] == \"active\"])\n",
    "    else:\n",
    "        return len(something[something[\"status\"] == \"inactive\"])\n",
    "\n",
    "\n",
    "def uptime_or_downtime_last_day(uptime: bool = True):\n",
    "    df.sort_values(\"timestamp_utc\", ascending=False, inplace=True)\n",
    "    current_day = df[\"timestamp_utc\"].iat[0]\n",
    "    till_day = current_day - datetime.timedelta(days=7)\n",
    "    from_dates = df.loc[df[\"timestamp_utc\"] > till_day]\n",
    "    nearest_till_day = from_dates.iloc[-1][\"timestamp_utc\"]\n",
    "    something = df.query(\"@nearest_till_day <= timestamp_utc <= @current_day\")\n",
    "    active_minutes = 0\n",
    "    inactive_minutes = 0\n",
    "\n",
    "    for index, row in something.iterrows():\n",
    "        delta = False\n",
    "        normal = False\n",
    "        aware_timestamp = row[\"timestamp_utc\"].replace(tzinfo=pytz.utc)\n",
    "        week_day = aware_timestamp.weekday()\n",
    "        active_week_day = row['day']\n",
    "        aware_start_time = convert_to_utc(\n",
    "            row[\"timezone_str\"], row[\"start_time_local\"], sample_date=aware_timestamp\n",
    "        ).replace(\n",
    "            year=aware_timestamp.year,\n",
    "            month=aware_timestamp.month,\n",
    "            day=aware_timestamp.day,\n",
    "        )\n",
    "        aware_end_time = convert_to_utc(\n",
    "            row[\"timezone_str\"], row[\"end_time_local\"], sample_date=aware_timestamp\n",
    "        ).replace(\n",
    "            year=aware_timestamp.year,\n",
    "            month=aware_timestamp.month,\n",
    "            day=aware_timestamp.day,\n",
    "        )\n",
    "        if aware_end_time < aware_start_time:\n",
    "            aware_end_time = aware_end_time + datetime.timedelta(days=1)\n",
    "            normal = aware_start_time <= aware_timestamp <= aware_end_time\n",
    "            if aware_end_time - aware_start_time == datetime.timedelta(\n",
    "                days=0, hours=23, minutes=59, seconds=59\n",
    "            ):\n",
    "                aware_end_time = aware_end_time - datetime.timedelta(days=2)\n",
    "                delta = aware_end_time <= aware_timestamp <= aware_start_time\n",
    "\n",
    "        else:\n",
    "            normal = aware_start_time <= aware_timestamp <= aware_end_time\n",
    "\n",
    "        if row[\"status\"] == \"active\" and week_day == active_week_day:\n",
    "            if normal or delta:\n",
    "                active_minutes += 1\n",
    "        elif row[\"status\"] == \"inactive\" and week_day == active_week_day:\n",
    "            if normal or delta:\n",
    "                inactive_minutes += 1\n",
    "\n",
    "    print(active_minutes / (60))\n",
    "    print(inactive_minutes / (60))\n",
    "    print((active_minutes/(60*24)) + (inactive_minutes/(60*24)))\n",
    "    return something\n",
    "    # can't assume that all the active and inactive are continous\n",
    "    # if uptime:\n",
    "    #     active = something[something['status'] == \"active\"]\n",
    "    #     if(len(active) != 0):\n",
    "    #         return str(active['timestamp_utc'].iat[0] - active['timestamp_utc'].iat[-1]).split(\" \")[-1]\n",
    "    #     else:\n",
    "    #         return '00:00:00'\n",
    "    # else:\n",
    "    #     inactive = something[something['status'] == \"inactive\"]\n",
    "    #     if(len(inactive) != 0):\n",
    "    #         return str(inactive['timestamp_utc'].iat[0] - inactive['timestamp_utc'].iat[-1]).split(\" \")[-1]\n",
    "    #     else:\n",
    "    #         return '00:00:00'\n",
    "\n",
    "\n",
    "def convert_to_utc(\n",
    "    timezone_str: str, date: datetime.datetime, sample_date: datetime.datetime\n",
    ") -> datetime.datetime:\n",
    "    # sample_date is important as the result varies as the month changes\n",
    "    date = date.replace(\n",
    "        year=sample_date.year, day=sample_date.day, month=sample_date.month\n",
    "    )\n",
    "    tz = pytz.timezone(timezone_str)\n",
    "    local_aware_time = tz.normalize(tz.localize(date, is_dst=False))\n",
    "    as_utc = local_aware_time.astimezone(pytz.UTC)\n",
    "    return as_utc\n",
    "\n",
    "\n",
    "hello_there = uptime_or_downtime_last_day(uptime=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823058"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mtimestamp_utc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m\"\u001b[39m\u001b[39mtimestamp_utc\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mstart_time_local\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m\"\u001b[39m\u001b[39mstart_time_local\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mend_time_local\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(df[\u001b[39m\"\u001b[39m\u001b[39mend_time_local\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"start_time_local\"] = pd.to_datetime(df[\"start_time_local\"], format=\"%H:%M:%S\")\n",
    "df[\"end_time_local\"] = pd.to_datetime(df[\"end_time_local\"], format=\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./result.csv')\n",
    "spark = SparkSession.builder.appName('hello').getOrCreate()\n",
    "spark.read.option(\"header\", True).csv(\"./result.csv\").createOrReplaceTempView('result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+------+--------------------+----+----------------+--------------+-------------------+\n",
      "|_c0|           store_id|status|       timestamp_utc| day|start_time_local|end_time_local|       timezone_str|\n",
      "+---+-------------------+------+--------------------+----+----------------+--------------+-------------------+\n",
      "|  0|8419537941919820732|active|2023-01-22 12:09:...|null|            null|          null|               null|\n",
      "|  1|  54515546588432327|active|2023-01-24 09:06:...| 0.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  2|  54515546588432327|active|2023-01-24 09:06:...| 6.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  3|  54515546588432327|active|2023-01-24 09:06:...| 5.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  4|  54515546588432327|active|2023-01-24 09:06:...| 2.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  5|  54515546588432327|active|2023-01-24 09:06:...| 3.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  6|  54515546588432327|active|2023-01-24 09:06:...| 4.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  7|  54515546588432327|active|2023-01-24 09:06:...| 1.0|        08:00:00|      18:30:00|   America/New_York|\n",
      "|  8|8377465688456570187|active|2023-01-24 09:07:...| 2.0|        09:00:00|      21:30:00|America/Los_Angeles|\n",
      "|  9|8377465688456570187|active|2023-01-24 09:07:...| 0.0|        09:00:00|      21:30:00|America/Los_Angeles|\n",
      "| 10|8377465688456570187|active|2023-01-24 09:07:...| 1.0|        09:00:00|      21:30:00|America/Los_Angeles|\n",
      "| 11|8377465688456570187|active|2023-01-24 09:07:...| 3.0|        09:00:00|      21:30:00|America/Los_Angeles|\n",
      "| 12|8377465688456570187|active|2023-01-24 09:07:...| 6.0|        10:00:00|      21:30:00|America/Los_Angeles|\n",
      "| 13|8377465688456570187|active|2023-01-24 09:07:...| 5.0|        10:00:00|      22:30:00|America/Los_Angeles|\n",
      "| 14|8377465688456570187|active|2023-01-24 09:07:...| 4.0|        09:00:00|      22:30:00|America/Los_Angeles|\n",
      "| 15|5955337179846162144|active|2023-01-24 09:08:...| 6.0|        11:30:00|      21:30:00|   America/New_York|\n",
      "| 16|5955337179846162144|active|2023-01-24 09:08:...| 0.0|        11:30:00|      21:30:00|   America/New_York|\n",
      "| 17|5955337179846162144|active|2023-01-24 09:08:...| 2.0|        11:30:00|      21:30:00|   America/New_York|\n",
      "| 18|5955337179846162144|active|2023-01-24 09:08:...| 3.0|        11:30:00|      21:30:00|   America/New_York|\n",
      "| 19|5955337179846162144|active|2023-01-24 09:08:...| 4.0|        11:30:00|      21:30:00|   America/New_York|\n",
      "+---+-------------------+------+--------------------+----+----------------+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(spark.sql(\"SELECT * FROM result\").show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14092\n",
      "132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINALIZED\n",
    "\n",
    "import datetime\n",
    "from pyspark.sql.functions import udf, col, to_timestamp\n",
    "from pyspark.sql.types import TimestampType, StringType\n",
    "\n",
    "\n",
    "def convert_to_utc(\n",
    "    timezone_str: str, date: datetime.datetime, sample_date: datetime.datetime\n",
    ") -> datetime.datetime:\n",
    "    # sample_date is important as the result varies as the month changes\n",
    "    date = date.replace(\n",
    "        year=sample_date.year, day=sample_date.day, month=sample_date.month\n",
    "    )\n",
    "    tz = pytz.timezone(timezone_str)\n",
    "    local_aware_time = tz.normalize(tz.localize(date, is_dst=False))\n",
    "    as_utc = local_aware_time.astimezone(pytz.UTC)\n",
    "    return as_utc\n",
    "\n",
    "\n",
    "# change in thinking\n",
    "# lets just take one store right now\n",
    "unique_store_ids = result[\"store_id\"].unique()\n",
    "print(len(unique_store_ids))\n",
    "\n",
    "def replaceUTCStr(string: str):\n",
    "    return string.replace(\" UTC\", \"\")\n",
    "\n",
    "\n",
    "def replaceLocalTimeStr(string: str):\n",
    "    return convert_to_utc(\n",
    "        sample_timezone, datetime.datetime.strptime(string, \"%H:%M:%S\"), sample_date\n",
    "    )\n",
    "\n",
    "\n",
    "udf_replaceUtcStr = udf(replaceUTCStr, StringType())\n",
    "udf_replaceLocalTimeStr = udf(replaceLocalTimeStr, TimestampType())\n",
    "sample_date = None\n",
    "sample_timezone = None\n",
    "\n",
    "selected_store_id = 10913998916849586\n",
    "# subset = spark.sql(f'SELECT * FROM result WHERE store_id == {selected_store_id}')\n",
    "# sample_date = subset.first()['timestamp_utc']\n",
    "# sample_timezone = subset.first()['timezone_str']\n",
    "# subset.withColumn(\"timestamp_utc\", udf_replaceUtcStr('timestamp_utc'))\n",
    "# subset.select(col('timestamp_utc'), to_timestamp(col(\"timestamp_utc\"), \"yyyy-dd-MM HH24:mm:ss.SSSSSS\")).show()\n",
    "# spark_df = spark.createDataFrame(result)\n",
    "hello = result.query(\"store_id == @selected_store_id\").copy()\n",
    "print(len(hello))\n",
    "hello[\"timestamp_utc\"] = hello[\"timestamp_utc\"].str.replace(\" UTC\", \"\")\n",
    "hello[\"timestamp_utc\"] = pd.to_datetime(\n",
    "    hello[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S.%f\"\n",
    ")\n",
    "hello[\"day\"] = hello[\"day\"].astype(int)\n",
    "hello[\"timestamp_utc\"] = pd.to_datetime(\n",
    "    hello[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "hello[\"start_time_local\"] = pd.to_datetime(hello[\"start_time_local\"], format=\"%H:%M:%S\")\n",
    "hello[\"end_time_local\"] = pd.to_datetime(hello[\"end_time_local\"], format=\"%H:%M:%S\")\n",
    "counter = 0\n",
    "hello.sort_values(\"timestamp_utc\", ascending=False, inplace=True)\n",
    "sample_date = hello[\"timestamp_utc\"].iat[0]\n",
    "sample_timezone = hello[\"timezone_str\"].iat[0]\n",
    "hello[\"start_time_local\"] = hello[\"start_time_local\"].apply(\n",
    "    lambda x: x.replace(\n",
    "        year=sample_date.year, month=sample_date.month, day=sample_date.day\n",
    "    )\n",
    ")\n",
    "hello[\"end_time_local\"] = hello[\"end_time_local\"].apply(\n",
    "    lambda x: x.replace(\n",
    "        year=sample_date.year, month=sample_date.month, day=sample_date.day\n",
    "    )\n",
    ")\n",
    "# hello[\"start_time_local\"] = (\n",
    "#     hello[\"start_time_local\"].dt.tz_localize(sample_timezone).dt.tz_convert(pytz.UTC)\n",
    "# )\n",
    "# hello[\"end_time_local\"] = (\n",
    "#     hello[\"end_time_local\"].dt.tz_localize(sample_timezone).dt.tz_convert(pytz.UTC)\n",
    "# )\n",
    "for index, row in hello.iterrows():\n",
    "    delta = False\n",
    "    normal = False\n",
    "    aware_timestamp = row[\"timestamp_utc\"].replace(tzinfo=pytz.utc)\n",
    "    aware_start_time = convert_to_utc(\n",
    "        row[\"timezone_str\"], row[\"start_time_local\"], sample_date=aware_timestamp\n",
    "    ).replace(\n",
    "        year=aware_timestamp.year,\n",
    "        month=aware_timestamp.month,\n",
    "        day=aware_timestamp.day,\n",
    "    )\n",
    "    aware_end_time = convert_to_utc(\n",
    "        row[\"timezone_str\"], row[\"end_time_local\"], sample_date=aware_timestamp\n",
    "    ).replace(\n",
    "        year=aware_timestamp.year,\n",
    "        month=aware_timestamp.month,\n",
    "        day=aware_timestamp.day,\n",
    "    )\n",
    "    if aware_end_time < aware_start_time:\n",
    "        aware_end_time = aware_end_time + datetime.timedelta(days=1)\n",
    "        normal = aware_start_time <= aware_timestamp <= aware_end_time\n",
    "        if aware_end_time - aware_start_time == datetime.timedelta(\n",
    "            days=0, hours=23, minutes=59, seconds=59\n",
    "        ):\n",
    "            aware_end_time = aware_end_time - datetime.timedelta(days=2)\n",
    "            delta = aware_end_time <= aware_timestamp <= aware_start_time\n",
    "\n",
    "    # print(row[\"timestamp_utc\"].weekday(), row[\"day\"])\n",
    "    if row[\"timestamp_utc\"].weekday() != row[\"day\"] or (not delta and not normal):\n",
    "        row.start_time_local = aware_start_time\n",
    "        hello.drop(index, inplace=True)\n",
    "    else:\n",
    "        hello.loc[index, \"start_time_local\"] = aware_start_time\n",
    "        hello.loc[index, \"end_time_local\"] = aware_end_time\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "len(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store_id\n",
      "status\n",
      "timestamp_utc\n",
      "day\n",
      "start_time_local\n",
      "end_time_local\n",
      "timezone_str\n"
     ]
    }
   ],
   "source": [
    "for value in hello:\n",
    "  print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-22 03:05:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-22 03:06:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-22 03:07:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22 03:08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-22 03:09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2023-01-22 13:05:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2023-01-22 13:06:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>2023-01-22 13:07:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2023-01-22 13:08:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2023-01-22 13:09:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>605 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp_utc   0\n",
       "0   2023-01-22 03:05:00 NaN\n",
       "1   2023-01-22 03:06:00 NaN\n",
       "2   2023-01-22 03:07:00 NaN\n",
       "3   2023-01-22 03:08:00 NaN\n",
       "4   2023-01-22 03:09:00 NaN\n",
       "..                  ...  ..\n",
       "600 2023-01-22 13:05:00 NaN\n",
       "601 2023-01-22 13:06:00 NaN\n",
       "602 2023-01-22 13:07:00 NaN\n",
       "603 2023-01-22 13:08:00 NaN\n",
       "604 2023-01-22 13:09:00 NaN\n",
       "\n",
       "[605 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FINALIZED\n",
    "\n",
    "ts = pd.Series(index=hello['timestamp_utc'])\n",
    "ts = ts.resample('T').mean()\n",
    "ts.interpolate(method='spline', order = 3)\n",
    "ts = ts.reset_index()\n",
    "hello.sort_values('timestamp_utc', ascending=True, inplace=True)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINALIZED\n",
    "\n",
    "from io import StringIO\n",
    "from csv import writer\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "output = StringIO()\n",
    "csv_writer = writer(output)\n",
    "header = False\n",
    "counter = 0\n",
    "\n",
    "# for index, row in temp.iterrows():\n",
    "#     if(not header):\n",
    "#       csv_writer.writerow(temp)\n",
    "#       header = True\n",
    "\n",
    "#     csv_writer.writerow(row)\n",
    "#     counter += 1\n",
    "current_store_id = np.nan\n",
    "current_status = np.nan\n",
    "current_day = np.nan\n",
    "current_start_time = np.nan\n",
    "current_end_time = np.nan\n",
    "current_timezone = np.nan\n",
    "\n",
    "for value in ts[\"timestamp_utc\"]:\n",
    "    if not header:\n",
    "        csv_writer.writerow(hello)\n",
    "        header = True\n",
    "    next_value = hello[\"timestamp_utc\"].iat[counter]\n",
    "    if value == next_value.replace(second=0, microsecond=0):\n",
    "        current_store_id = hello[\"store_id\"].iat[counter]\n",
    "        current_status = hello[\"status\"].iat[counter]\n",
    "        current_day = hello[\"day\"].iat[counter]\n",
    "        current_start_time = hello[\"start_time_local\"].iat[counter]\n",
    "        current_end_time = hello[\"end_time_local\"].iat[counter]\n",
    "        current_timezone = hello[\"timezone_str\"].iat[counter]\n",
    "        # temp_dict = {\n",
    "        #     \"store_id\": current_store_id,\n",
    "        #     \"status\": current_status,\n",
    "        #     \"timestamp_utc\": value,\n",
    "        #     \"day\": current_day,\n",
    "        #     \"start_time_local\": current_start_time,\n",
    "        #     \"end_time_local\": current_end_time,\n",
    "        #     \"timezone_str\": current_timezone,\n",
    "        # }\n",
    "        temp_list = [current_store_id, current_status, value, current_day, current_start_time, current_end_time, current_timezone]\n",
    "        csv_writer.writerow(temp_list)\n",
    "        counter += 1\n",
    "    else:\n",
    "        # temp_dict = {\n",
    "        #     \"store_id\": current_store_id,\n",
    "        #     \"status\": current_status,\n",
    "        #     \"timestamp_utc\": value,\n",
    "        #     \"day\": current_day,\n",
    "        #     \"start_time_local\": current_start_time,\n",
    "        #     \"end_time_local\": current_end_time,\n",
    "        #     \"timezone_str\": current_timezone,\n",
    "        # }\n",
    "        temp_list = [current_store_id, current_status, value, current_day, current_start_time, current_end_time, current_timezone]\n",
    "        csv_writer.writerow(temp_list)\n",
    "\n",
    "output.seek(0)  # we need to get back to the start of the BytesIO\n",
    "df = pd.read_csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4417\n",
      "5654\n"
     ]
    }
   ],
   "source": [
    "print(len(df.query('status == \"active\"')))\n",
    "print(len(df.query('status == \"inactive\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4201388888888889\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# FINALIZED\n",
    "\n",
    "df.sort_values(\"timestamp_utc\", ascending=False, inplace=True)\n",
    "df[\"timestamp_utc\"] = pd.to_datetime(df[\"timestamp_utc\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "# df\n",
    "current_date = df['timestamp_utc'].iat[0]\n",
    "till_date = current_date - datetime.timedelta(days=7)\n",
    "from_dates = df.loc[df[\"timestamp_utc\"] > till_date]\n",
    "nearest_till_date = from_dates.iloc[-1]['timestamp_utc']\n",
    "required_df = df.query('@nearest_till_date <= timestamp_utc <= @current_date')\n",
    "print(len(required_df.query('status == \"active\"')) / (60 * 24))\n",
    "print(len(required_df.query('status == \"inactive\"')) / (60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
